{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GPUID='0'##调用GPU序号\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = GPUID\n",
    "import torch\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "def plot_box(img,boxes):\n",
    "    blue = (0, 0, 0) #18\n",
    "    tmp = np.copy(img)\n",
    "    for box in boxes:\n",
    "         cv2.rectangle(tmp, (int(box[0]),int(box[1])), (int(box[2]), int(box[3])), blue, 1) #19\n",
    "    \n",
    "    return Image.fromarray(tmp) \n",
    "\n",
    "def plot_boxes(img,angle, result,color=(0,0,0)):\n",
    "    tmp = np.array(img)\n",
    "    c = color\n",
    "    w,h = img.size\n",
    "    thick = int((h + w) / 300)\n",
    "    i = 0\n",
    "    if angle in [90,270]:\n",
    "        imgW,imgH = img.size[::-1]\n",
    "        \n",
    "    else:\n",
    "        imgW,imgH = img.size\n",
    "\n",
    "    for line in result:\n",
    "        cx =line['cx']\n",
    "        cy = line['cy']\n",
    "        degree =line['degree']\n",
    "        w  = line['w']\n",
    "        h = line['h']\n",
    "\n",
    "        x1,y1,x2,y2,x3,y3,x4,y4 = model.xy_rotate_box(cx, cy, w, h, degree/180*np.pi)\n",
    "        \n",
    "        x1,y1,x2,y2,x3,y3,x4,y4 = model.box_rotate([x1,y1,x2,y2,x3,y3,x4,y4],angle=(360-angle)%360,imgH=imgH,imgW=imgW)\n",
    "        cx  =np.mean([x1,x2,x3,x4])\n",
    "        cy  = np.mean([y1,y2,y3,y4])\n",
    "        cv2.line(tmp,(int(x1),int(y1)),(int(x2),int(y2)),c,5)\n",
    "        cv2.line(tmp,(int(x2),int(y2)),(int(x3),int(y3)),c,5)\n",
    "        cv2.line(tmp,(int(x3),int(y3)),(int(x4),int(y4)),c,5)\n",
    "        cv2.line(tmp,(int(x4),int(y4)),(int(x1),int(y1)),c,5)\n",
    "        mess=str(i)\n",
    "        cv2.putText(tmp, mess, (int(cx), int(cy)),0, 1e-3 * h, c, thick // 2)\n",
    "        i+=1\n",
    "    return Image.fromarray(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect take:1.721271276473999s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'newW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7b18741340ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                     \u001b[0mrightAdjust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m##对检测的文本行进行向右延伸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                     \u001b[0malph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m##对检测的文本行进行向右、左延伸的倍数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                     \u001b[0mifadjustDegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                                    )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/service/OCR/yolov3/model.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(img, detectAngle, config, leftAdjust, rightAdjust, alph, ifadjustDegree)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Detect take:{}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeTake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mnewBox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_recs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrnnRec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewBox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleftAdjust\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrightAdjust\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/service/OCR/yolov3/model.py\u001b[0m in \u001b[0;36mcrnnRec\u001b[0;34m(im, boxes, leftAdjust, rightAdjust, alph, f)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#        if simPred.strip()!=u'':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#             results.append({'cx':cx*f,'cy':cy*f,'text':simPred,'w':newW*f,'h':newH*f,'degree':degree*180.0/np.pi})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m        \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnewW\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnewH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'degree'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m180.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'newW' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PIL import Image\n",
    "p = '/home/datalab/ex_disk/work/shengdan/dataset/poster/allimg/26161.png'\n",
    "img = Image.open(p).convert(\"RGB\")\n",
    "w,h = img.size\n",
    "timeTake = time.time()\n",
    "_,result,angle= model.model(img,\n",
    "                                    detectAngle=False,##是否进行文字方向检测\n",
    "                                    config=dict(MAX_HORIZONTAL_GAP=100,##字符之间的最大间隔，用于文本行的合并\n",
    "                                    MIN_V_OVERLAPS=0.7,\n",
    "                                    MIN_SIZE_SIM=0.7,\n",
    "                                    TEXT_PROPOSALS_MIN_SCORE=0.1,\n",
    "                                    TEXT_PROPOSALS_NMS_THRESH=0.3,\n",
    "                                    TEXT_LINE_NMS_THRESH = 0.99,##文本行之间测iou值\n",
    "                                    MIN_RATIO=1.0,\n",
    "                                    LINE_MIN_SCORE=0.1,\n",
    "                                    TEXT_PROPOSALS_WIDTH=0,\n",
    "                                    MIN_NUM_PROPOSALS=0,                                               \n",
    "                ),\n",
    "                                    leftAdjust=True,##对检测的文本行进行向左延伸\n",
    "                                    rightAdjust=True,##对检测的文本行进行向右延伸\n",
    "                                    alph=0.1,##对检测的文本行进行向右、左延伸的倍数\n",
    "                                    ifadjustDegree=False\n",
    "                                   )\n",
    "        \n",
    "timeTake = time.time()-timeTake\n",
    "\n",
    "print('It take:{}s'.format(timeTake))\n",
    "for line in result:\n",
    "    print(line)\n",
    "plot_boxes(img,angle, result,color=(200,200,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36(shengdan)",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
